Initial data exploration revealed inconsistencies within categorical features, specifically file extensions. These were addressed through standardization and then encoded using a multi-label binarizer. This step was crucial as file types often indicate development roles (e.g., .py for backend, .html for frontend).When EDA was done i exploded the list to get a better picture however for modelling i used the multi-label binarizer.
For numerical features, such as lines added or files changed, an initial binning approach (e.g., tiny, small, medium) was considered. However, visual analysis of the data, which exhibited highly skewed distributions, indicated that this approach would lead to significant information loss. Then I applied log transformations  to normalize these distributions. Additionally, new features like net churn  (lines added minus deleted) and files per line (commit size) were engineered. These derived features offered enhanced interpretability and provided better insights into varying commit behaviors.
Model selection prioritized a balance between interpretability and effectiveness. Gaussian Naive Bayes served as a foundational model. Multinomial Naive Bayes demonstrated strong performance when applied to commit messages, leveraging a Bag-of-Words representation, underscoring the predictive power of textual data. Ultimately, Random Forest was chosen due to its ability to seamlessly integrate diverse feature types (textual, numerical, categorical) without requiring assumptions about their interdependencies.
The experiments showed that commit messages alone can achieve very high accuracy, but I kept numeric and categorical features because they improve robustness and interpretability. Overall, this project reminded me that reasoning and careful design are as important as final scores, and that documenting every step is what makes results reproducible and trustworthy.
